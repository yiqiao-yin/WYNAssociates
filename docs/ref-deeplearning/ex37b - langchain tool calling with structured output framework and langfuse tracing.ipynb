{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7aLTYjWk8EjIwou3OHngN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This system is a lightweight yet powerful conversational AI pipeline built for structured interactions and observability. It leverages **OpenAI** as the primary language model, ensuring robust natural language understanding and generation. **LangChain** orchestrates the agentic workflow by managing tool usage, chaining logic, and invoking custom functions when specific user intents are detected. For output consistency and validation, the system uses **Pydantic**, enabling reliable and typed structured responses that can be logged or passed downstream. To provide deep observability, **Langfuse** is integrated into the pipeline, capturing every interaction, tool invocation, and agent decision in real time. This allows developers to trace, debug, and analyze conversations with full transparency through the Langfuse UI. The modular design enables easy extension with additional tools, and the LangChain + Langfuse integration ensures that both execution logic and telemetry are fully synchronized. The result is a flexible and transparent agent framework suitable for production-facing applications.\n","\n","Here‚Äôs the same content summarized into bullet points with emojis:\n","\n","* ü§ñ **LLM**: Uses OpenAI's GPT-4 for natural language understanding and generation.\n","* üß† **LangChain**: Manages agentic workflow and tool invocation dynamically based on user input.\n","* üì¶ **Pydantic**: Ensures structured, type-safe responses for downstream reliability and logging.\n","* üîç **Langfuse**: Provides observability by tracing interactions, tool calls, and agent behavior.\n","* üß± **Modular Design**: Easily extendable with additional tools or APIs.\n","* üìä **Transparent Debugging**: All conversation flows and decisions visible in Langfuse UI.\n","* üöÄ **Production Ready**: Ideal for CLI tools, support agents, or integrated customer-facing apps.\n"],"metadata":{"id":"dLVWaQV7dmoZ"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OnRZcmOZdDhs","executionInfo":{"status":"ok","timestamp":1750525702793,"user_tz":240,"elapsed":19334,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"53e30be6-1cdd-454d-c2ea-e134eee5100b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.86.0)\n","Collecting dateparser\n","  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n","Collecting langfuse\n","  Downloading langfuse-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2025.2)\n","Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2024.11.6)\n","Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.3.1)\n","Collecting backoff>=1.10.0 (from langfuse)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse)\n","  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-exporter-otlp<2.0.0,>=1.33.1 (from langfuse)\n","  Downloading opentelemetry_exporter_otlp-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse)\n","  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: packaging<25.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langfuse) (24.2)\n","Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.11/dist-packages (from langfuse) (1.17.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse) (8.7.0)\n","Collecting opentelemetry-exporter-otlp-proto-grpc==1.34.1 (from opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-exporter-otlp-proto-http==1.34.1 (from opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.70.0)\n","Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.73.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n","Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.34.1->opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (5.29.5)\n","Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse) (3.23.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n","Downloading langchain_openai-0.3.24-py3-none-any.whl (68 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langfuse-3.0.3-py3-none-any.whl (292 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m292.7/292.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp-1.34.1-py3-none-any.whl (7.0 kB)\n","Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl (17 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: opentelemetry-proto, backoff, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, dateparser, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, opentelemetry-exporter-otlp, langfuse\n","Successfully installed backoff-2.2.1 dateparser-1.2.1 langchain-openai-0.3.24 langfuse-3.0.3 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-exporter-otlp-proto-http-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1\n"]}],"source":["pip install langchain langchain-openai openai dateparser langfuse"]},{"cell_type":"code","source":["from google.colab import userdata\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"8O4UL2HKdcuN","executionInfo":{"status":"ok","timestamp":1750525705089,"user_tz":240,"elapsed":2289,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Replace with your actual key or keep as-is if it's already in a variable\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"],"metadata":{"id":"bHbMNnfAdflU","executionInfo":{"status":"ok","timestamp":1750525705104,"user_tz":240,"elapsed":6,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","LangChain chatbot with tool invocation, now integrated with Langfuse tracing.\n","\"\"\"\n","\n","import os\n","from typing import Callable, Dict, List, Tuple, Optional\n","\n","from pydantic import BaseModel\n","from langchain_core.tools import Tool\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain.agents import create_openai_functions_agent, AgentExecutor\n","\n","from langfuse import Langfuse, get_client\n","from langfuse.langchain import CallbackHandler\n","\n","# Initialize Langfuse tracing client at startup\n","Langfuse(\n","    public_key=os.environ.get(\"LANGFUSE_PUBLIC_KEY\", \"pk-lf-xxx\"),\n","    secret_key=os.environ.get(\"LANGFUSE_SECRET_KEY\", \"sk-lf-xxx\"),\n","    host=os.environ.get(\"LANGFUSE_HOST\", \"https://us.cloud.langfuse.com\"),\n",")\n","langfuse = get_client()\n","langfuse_handler = CallbackHandler()\n","\n","# Global list to track tool usage during each interaction\n","TOOL_USAGE_LOG: List[str] = []\n","\n","\n","class ChatbotResponse(BaseModel):\n","    \"\"\"\n","    Structured output of the chatbot for logging or downstream usage.\n","    \"\"\"\n","    thought: str\n","    message: str\n","    tools: List[str]\n","\n","\n","def tracked_tool(name: str, func: Callable[[str], str]) -> Callable[[str], str]:\n","    \"\"\"\n","    Wraps a tool function to log its name when called.\n","\n","    Args:\n","        name: Tool identifier.\n","        func: Underlying processing function.\n","\n","    Returns:\n","        Wrapper that logs usage and invokes the tool.\n","    \"\"\"\n","    def wrapper(input_text: str) -> str:\n","        TOOL_USAGE_LOG.append(name)\n","        return func(input_text)\n","    return wrapper\n","\n","\n","def simple_calculator(query: str) -> str:\n","    \"\"\"\n","    Evaluates a math expression.\n","\n","    Args:\n","        query: Expression string.\n","\n","    Returns:\n","        Computed result or error message.\n","    \"\"\"\n","    try:\n","        result: float = eval(query, {\"__builtins__\": {}})\n","        return str(result)\n","    except Exception as err:\n","        return f\"Error in calculation: {err}\"\n","\n","\n","def get_calculator_tool() -> Tool:\n","    \"\"\"\n","    Builds calculator tool with logging wrapper.\n","\n","    Returns:\n","        Tool instance.\n","    \"\"\"\n","    return Tool(\n","        name=\"Calculator\",\n","        description=\"Evaluates basic math expressions.\",\n","        func=tracked_tool(\"Calculator\", simple_calculator),\n","    )\n","\n","\n","def list_suicide_hotlines(_: str) -> str:\n","    \"\"\"\n","    Returns suicide hotline info.\n","\n","    Args:\n","        _: Placeholder input.\n","\n","    Returns:\n","        Hotline list string.\n","    \"\"\"\n","    return (\n","        \"\\U0001F4DE Suicide Prevention Hotlines:\\n\"\n","        \"- US National: 1-800-273-TALK (8255)\\n\"\n","        \"- Crisis Text Line: Text HOME to 741741\\n\"\n","        \"- SAMHSA: 1-800-662-HELP\\n\"\n","        \"- TrevorLifeline: 1-866-488-7386\\n\"\n","        \"- Intl Directory: https://www.opencounseling.com/suicide-hotlines\"\n","    )\n","\n","\n","def get_hotlines_tool() -> Tool:\n","    \"\"\"\n","    Builds hotline tool with logging wrapper.\n","\n","    Returns:\n","        Tool instance.\n","    \"\"\"\n","    return Tool(\n","        name=\"SuicideHotlines\",\n","        description=\"Provides suicide prevention hotline numbers.\",\n","        func=tracked_tool(\"SuicideHotlines\", list_suicide_hotlines),\n","    )\n","\n","\n","def get_llm() -> ChatOpenAI:\n","    \"\"\"\n","    Initializes the OpenAI chat model.\n","\n","    Returns:\n","        ChatOpenAI instance.\n","\n","    Raises:\n","        ValueError: If the API key is not set.\n","    \"\"\"\n","    api_key: Optional[str] = os.environ.get(\"OPENAI_API_KEY\")\n","    if not api_key:\n","        raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n","    return ChatOpenAI(model=\"gpt-4\", temperature=0.0, openai_api_key=api_key)\n","\n","\n","def get_prompt() -> ChatPromptTemplate:\n","    \"\"\"\n","    Constructs and returns the prompt structure for the agent.\n","    \"\"\"\n","    return ChatPromptTemplate.from_messages([\n","        (\"system\", \"You are a helpful assistant that can use tools.\"),\n","        (\"user\", \"{input}\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ])\n","\n","\n","def get_agent_chain_and_tools() -> Tuple[AgentExecutor, List[Tool]]:\n","    \"\"\"\n","    Constructs the AgentExecutor with Langfuse callback for tracing.\n","\n","    Returns:\n","        Tuple of AgentExecutor and list of tool instances.\n","    \"\"\"\n","    llm = get_llm()\n","    tools = [get_calculator_tool(), get_hotlines_tool()]\n","    prompt = get_prompt()\n","\n","    # Create a tool-enabled agent\n","    agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)\n","\n","    # Attach Langfuse tracing callback\n","    agent_executor = AgentExecutor(\n","        agent=agent,\n","        tools=tools,\n","        verbose=True,\n","        callbacks=[langfuse_handler],\n","    )\n","\n","    return agent_executor, tools\n","\n","\n","def run_chat_loop(agent_chain: AgentExecutor, tools: List[Tool]) -> None:\n","    \"\"\"\n","    Runs the interactive CLI loop, tracing each message.\n","\n","    Args:\n","        agent_chain: Configured AgentExecutor with tracing.\n","        tools: Available tool instances.\n","    \"\"\"\n","    print(\"Chatbot is ready. Type 'exit' to quit.\")\n","    while True:\n","        user_input: str = input(\"User: \")\n","        if user_input.lower() in {\"exit\", \"quit\"}:\n","            print(\"Exiting chatbot.\")\n","            break\n","\n","        try:\n","            TOOL_USAGE_LOG.clear()\n","            raw_response: Dict[str, str] = agent_chain.invoke({\"input\": user_input})\n","            used_tools = TOOL_USAGE_LOG.copy()\n","\n","            thought = (\n","                f\"Processed using tool(s): {', '.join(used_tools)}\"\n","                if used_tools else \"No tools used.\"\n","            )\n","\n","            structured = ChatbotResponse(\n","                thought=thought,\n","                message=raw_response.get(\"output\", \"[No output]\"),\n","                tools=used_tools,\n","            )\n","            print(\"Structured Response:\", structured.model_dump_json(indent=2))\n","        except Exception as err:\n","            print(\"Error during chat:\", err)\n","    # Flush trace data to Langfuse so it appears in the UI\n","    langfuse.flush()\n","\n","\n","if __name__ == \"__main__\":\n","    agent_chain, tool_list = get_agent_chain_and_tools()\n","    run_chat_loop(agent_chain, tool_list)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ov53LYx0dgAm","executionInfo":{"status":"ok","timestamp":1750525831630,"user_tz":240,"elapsed":73678,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"f314f015-517e-4827-d3c8-658ea96158b6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Chatbot is ready. Type 'exit' to quit.\n","User: what's the capital of england?\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32;1m\u001b[1;3mThe capital of England is London.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Structured Response: {\n","  \"thought\": \"No tools used.\",\n","  \"message\": \"The capital of England is London.\",\n","  \"tools\": []\n","}\n","User: my name is Yiqiao, how many letters are there in my name?\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `Calculator` with `6`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m6\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n","WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32;1m\u001b[1;3mYour name, Yiqiao, has 6 letters.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Structured Response: {\n","  \"thought\": \"Processed using tool(s): Calculator\",\n","  \"message\": \"Your name, Yiqiao, has 6 letters.\",\n","  \"tools\": [\n","    \"Calculator\"\n","  ]\n","}\n","User: what are some suicidal hotlines? I don't feel good\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `SuicideHotlines` with `global`\n","\n","\n","\u001b[0m\u001b[33;1m\u001b[1;3müìû Suicide Prevention Hotlines:\n","- US National: 1-800-273-TALK (8255)\n","- Crisis Text Line: Text HOME to 741741\n","- SAMHSA: 1-800-662-HELP\n","- TrevorLifeline: 1-866-488-7386\n","- Intl Directory: https://www.opencounseling.com/suicide-hotlines\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n","WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32;1m\u001b[1;3mI'm really sorry that you're feeling this way, but I'm unable to provide the help that you need. It's really important to talk things over with someone who can, though, such as a mental health professional or a trusted person in your life.\n","\n","Here are some suicide prevention hotlines you can reach out to:\n","\n","- US National: 1-800-273-TALK (8255)\n","- Crisis Text Line: Text HOME to 741741\n","- SAMHSA: 1-800-662-HELP\n","- TrevorLifeline: 1-866-488-7386\n","\n","You can also find an international directory of suicide prevention hotlines at this link: [International Suicide Hotlines](https://www.opencounseling.com/suicide-hotlines)\n","\n","Please reach out to them, they are there to help you.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Structured Response: {\n","  \"thought\": \"Processed using tool(s): SuicideHotlines\",\n","  \"message\": \"I'm really sorry that you're feeling this way, but I'm unable to provide the help that you need. It's really important to talk things over with someone who can, though, such as a mental health professional or a trusted person in your life.\\n\\nHere are some suicide prevention hotlines you can reach out to:\\n\\n- US National: 1-800-273-TALK (8255)\\n- Crisis Text Line: Text HOME to 741741\\n- SAMHSA: 1-800-662-HELP\\n- TrevorLifeline: 1-866-488-7386\\n\\nYou can also find an international directory of suicide prevention hotlines at this link: [International Suicide Hotlines](https://www.opencounseling.com/suicide-hotlines)\\n\\nPlease reach out to them, they are there to help you.\",\n","  \"tools\": [\n","    \"SuicideHotlines\"\n","  ]\n","}\n","User: quit\n","Exiting chatbot.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JBBFG_rsd0lL"},"execution_count":null,"outputs":[]}]}