{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejWV0mVABToB"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qzAjGr759l4",
        "outputId": "59e11d25-0422-47a1-8e2d-c4edaec6a8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.4.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.13)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
            "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (1.26.4)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.1.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from together) (18.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.10.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.4.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.5/80.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: eval-type-backport, together\n",
            "Successfully installed eval-type-backport-0.2.2 together-1.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhF2Y56qBpq2"
      },
      "source": [
        "## API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0NIc0qjI6GYo"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gF_whsvt68Qv"
      },
      "outputs": [],
      "source": [
        "from together import Together\n",
        "\n",
        "class ChatBot:\n",
        "    \"\"\"\n",
        "    A simple ChatBot class to interact with a Together LLM model.\n",
        "\n",
        "    Attributes:\n",
        "        api_key (str): The API key used to authenticate with the Together API.\n",
        "        client (Together): A Together client for making requests.\n",
        "        history (list[dict]): A list of dictionaries representing the conversation history.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the ChatBot with a given API key and an empty conversation history.\n",
        "        Also creates a Together client instance for making requests.\n",
        "\n",
        "        Args:\n",
        "            api_key (str): The API key for Together.\n",
        "        \"\"\"\n",
        "        self.api_key: str = api_key\n",
        "        self.client: Together = Together(api_key=self.api_key)\n",
        "        self.history: list[dict] = []\n",
        "\n",
        "    def append_history(self, role: str, content: str) -> None:\n",
        "        \"\"\"\n",
        "        Appends a new message entry to the conversation history.\n",
        "\n",
        "        Args:\n",
        "            role (str): The role of the message sender, e.g., \"user\" or \"assistant\".\n",
        "            content (str): The message content to be appended.\n",
        "        \"\"\"\n",
        "        self.history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    def invoke_api(\n",
        "        self,\n",
        "        model: str = \"deepseek-ai/DeepSeek-V3\",\n",
        "        max_tokens: int = 1024,\n",
        "        temperature: float = 0.7,\n",
        "        top_p: float = 0.7,\n",
        "        top_k: int = 50,\n",
        "        repetition_penalty: float = 1.0,\n",
        "        stop: list[str] = [\"<ï½œendâ–ofâ–sentenceï½œ>\"]\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Invokes the Together chat API using the stored conversation history.\n",
        "\n",
        "        Args:\n",
        "            model (str, optional): The name of the Together model to use. Defaults to \"deepseek-ai/DeepSeek-V3\".\n",
        "            max_tokens (int, optional): The maximum number of tokens in the response. Defaults to 1024.\n",
        "            temperature (float, optional): The sampling temperature. Defaults to 0.7.\n",
        "            top_p (float, optional): The top_p sampling parameter. Defaults to 0.7.\n",
        "            top_k (int, optional): The top_k sampling parameter. Defaults to 50.\n",
        "            repetition_penalty (float, optional): The repetition penalty parameter. Defaults to 1.0.\n",
        "            stop (list[str], optional): A list of stop tokens. Defaults to [\"<ï½œendâ–ofâ–sentenceï½œ>\"].\n",
        "\n",
        "        Returns:\n",
        "            str: The collapsed string response from the API.\n",
        "        \"\"\"\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=self.history,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            stop=stop,\n",
        "            stream=True\n",
        "        )\n",
        "        answer: str = self.collapse_response(response)\n",
        "        return answer\n",
        "\n",
        "    def collapse_response(self, response) -> str:\n",
        "        \"\"\"\n",
        "        Collapses a streaming response from the Together API into a single string.\n",
        "\n",
        "        Args:\n",
        "            response: The streaming response object from the Together API.\n",
        "\n",
        "        Returns:\n",
        "            str: A single string containing the concatenated content from each token in the response.\n",
        "        \"\"\"\n",
        "        answer: str = \"\"\n",
        "        for token in response:\n",
        "            if hasattr(token, \"choices\"):\n",
        "                try:\n",
        "                    answer += token.choices[0].delta.content\n",
        "                except:\n",
        "                    pass\n",
        "        return answer\n",
        "\n",
        "    def show_history(self) -> None:\n",
        "        \"\"\"\n",
        "        Prints the entire conversation history.\n",
        "        \"\"\"\n",
        "        print(self.history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCWgkWerBrAD"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wNO0kOzdHm_W"
      },
      "outputs": [],
      "source": [
        "# # Instantiate the ChatBot\n",
        "# bot = ChatBot(api_key=TOGETHER_API_KEY)\n",
        "\n",
        "# bot.history = [{\"role\": \"assistant\", \"content\": \"You always provide reasoning. Your answer starts from <think>xxx</think> and <response>.\"}]\n",
        "\n",
        "# # Provided by data\n",
        "# current_question = \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
        "# current_answer = \"72\"\n",
        "# augmented_content = f\"Provide reasoning how to answer question: {current_question} and to arrive with answer: {current_answer}\"\n",
        "# print(augmented_content)\n",
        "\n",
        "# # Append augmented content to history\n",
        "# bot.append_history(role=\"user\", content=augmented_content)\n",
        "# bot.invoke_api()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pmHNkVaq8DrO"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# # Replace with your actual Together API key\n",
        "# # TOGETHER_API_KEY = \"YOUR_TOGETHER_API_KEY\"\n",
        "\n",
        "# # Instantiate the ChatBot\n",
        "# bot = ChatBot(api_key=TOGETHER_API_KEY)\n",
        "# print(\"Welcome to the ChatBot! Type 'exit' or 'quit' to end the conversation.\\n\")\n",
        "\n",
        "# while True:\n",
        "#     try:\n",
        "#         # Get user input\n",
        "#         user_input = input(\"ğŸ§‘â€ğŸ’» You: \")\n",
        "\n",
        "#         # Check for exit condition\n",
        "#         if user_input.strip().lower() in [\"exit\", \"quit\"]:\n",
        "#             print(\"ğŸ‘‹ Ending the conversation. Goodbye!\")\n",
        "#             break\n",
        "\n",
        "#         # Append user message to history\n",
        "#         bot.append_history(role=\"user\", content=user_input)\n",
        "\n",
        "#         # Invoke the API to get the assistant's response\n",
        "#         assistant_response = bot.invoke_api()\n",
        "\n",
        "#         # Append assistant response to history\n",
        "#         bot.append_history(role=\"assistant\", content=assistant_response)\n",
        "\n",
        "#         # Display the assistant's response with emoji\n",
        "#         print(f\"ğŸ¤– Assistant: {assistant_response}\\n\")\n",
        "\n",
        "#     except KeyboardInterrupt:\n",
        "#         print(\"\\nğŸ‘‹ Conversation interrupted. Goodbye!\")\n",
        "#         break\n",
        "#     except Exception as e:\n",
        "#         print(f\"âŒ An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxGG1Q10BtJ-"
      },
      "source": [
        "## Installation of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfCOZihHGVZ4",
        "outputId": "2ac4e72c-cfb4-4c94-f835-ef997eb67366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dtsbf1H6GKad"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load and prep dataset\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    return answer.strip()\n",
        "\n",
        "def extract_hash_answer(text: str) -> str | None:\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    return text.split(\"####\")[1].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e732aa70f49f4b4f8948cc026a4a0927",
            "adc432b07d9e4a3f85976a681ee5703b",
            "b225db327cb14cd692171f66add98c02",
            "082d77cdfd784312a727b29e3ef5be3a",
            "ffa06e7ae5b043d2877f14bb94c44835",
            "7e36dd68c17c4dc5834f55b96044baee",
            "0f72dfc66aa347868ca368a5dc293b3d",
            "bdb381237a53402d9921c11539413a56",
            "2e8850b73f304a9dafeb0a7aec22638b",
            "9a64c71058e44f6faa7299f2c8336958",
            "8812c2de0d48420ab86ecfb5f2f04e48"
          ]
        },
        "id": "MtJeQptB8ToZ",
        "outputId": "9e26bf84-ef8f-45c2-968d-686098d92eb3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e732aa70f49f4b4f8948cc026a4a0927"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the full dataset\n",
        "data = load_dataset('openai/gsm8k', 'main')\n",
        "\n",
        "# Select only the first 100 samples\n",
        "data = data['train'].select(range(2000))\n",
        "\n",
        "# Print dataset summary\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15932FwfR1gD"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr7v-wx9B_3m"
      },
      "source": [
        "## Prep for Augment Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWtoN7saKSVW"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm  # For progress tracking\n",
        "\n",
        "# Function to augment an answer using the ChatBot\n",
        "def augment_answer(example: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Takes a dictionary containing a 'question' and 'answer',\n",
        "    creates a new ChatBot instance with a clean history,\n",
        "    calls the ChatBot, and replaces the answer with the augmented response.\n",
        "\n",
        "    Args:\n",
        "    example (dict): A dictionary with keys 'question' and 'answer'.\n",
        "\n",
        "    Returns:\n",
        "    dict: The updated dictionary with an augmented 'answer'.\n",
        "    \"\"\"\n",
        "    # Instantiate a new ChatBot (clean slate)\n",
        "    bot = ChatBot(api_key=TOGETHER_API_KEY)\n",
        "\n",
        "    # Set up initial chatbot history\n",
        "    bot.history = [\n",
        "        {\"role\": \"assistant\", \"content\": \"You always provide reasoning. Your answer starts from <think>xxx</think> and <response>.\"}\n",
        "    ]\n",
        "\n",
        "    current_question = example[\"question\"]\n",
        "    current_answer = example[\"answer\"]\n",
        "\n",
        "    # Construct the augmented content\n",
        "    augmented_content = f\"Provide reasoning how to answer question: {current_question} and to arrive with answer: {current_answer}\"\n",
        "\n",
        "    # Append question to chatbot history\n",
        "    bot.append_history(role=\"user\", content=augmented_content)\n",
        "\n",
        "    attempts = 0\n",
        "    while attempts < 3:\n",
        "        try:\n",
        "            # Call API and get response\n",
        "            response = bot.invoke_api()\n",
        "            example[\"answer\"] = response  # Assign bot output to 'answer'\n",
        "            return example\n",
        "        except RateLimitError as e:\n",
        "            if attempts < 2:  # try up to 3 times\n",
        "                time.sleep(5)  # wait for 5 seconds before retrying\n",
        "            else:\n",
        "                example[\"answer\"] = \"NULL\"  # set response to NULL after 3 failed attempts\n",
        "                return example\n",
        "        attempts += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aXOn--OCMyI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Get the number of CPU cores\n",
        "num_cpus = os.cpu_count()\n",
        "\n",
        "# Print the result\n",
        "print(f\"Number of CPUs: {num_cpus}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRLmbV-IC8kT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the number of available GPUs\n",
        "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Print the result\n",
        "print(f\"Number of GPUs: {num_gpus}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E7GZCHjR-4t"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Apply the function to each row in the dataset\n",
        "data = data.map(augment_answer, num_proc=8)  # Parallel processing for speed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the updated dataset (optional)\n",
        "data.save_to_disk(\"augmented_gsm8k_2k\")"
      ],
      "metadata": {
        "id": "IWtexjHx3ztE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIBlHC0ASDR4"
      },
      "outputs": [],
      "source": [
        "# data = data.map(lambda x: { # type: ignore\n",
        "#         'prompt': [\n",
        "#             {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "#             {'role': 'user', 'content': x['question']}\n",
        "#         ],\n",
        "#         'answer': extract_hash_answer(x['answer'])\n",
        "#     }) # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBvP7KSxQs-_"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk, DatasetDict\n",
        "\n",
        "# Load dataset from the saved folder\n",
        "aug_data = load_from_disk(\"augmented_gsm8k_2k\")\n",
        "\n",
        "# Convert it into a DatasetDict format\n",
        "dataset_dict = DatasetDict({\"train\": aug_data})\n",
        "\n",
        "# Save again in correct structure\n",
        "dataset_dict.save_to_disk(\"augmented_gsm8k_2k\")\n",
        "\n",
        "# Define user and repo details\n",
        "user_name = \"eagle0504\"\n",
        "repo_name = \"openai-gsm8k-augmented-using-together-ai-deepseek-v3-train-enhanced-2k\"  # Change this to your desired repository name\n",
        "\n",
        "# Push to Hugging Face\n",
        "dataset_dict.push_to_hub(f\"{user_name}/{repo_name}\")\n",
        "\n",
        "# Print the URL of the pushed dataset\n",
        "print(f\"Dataset pushed to: https://huggingface.co/datasets/{user_name}/{repo_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22XZmE6_SgEl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "ejWV0mVABToB",
        "UhF2Y56qBpq2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e732aa70f49f4b4f8948cc026a4a0927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adc432b07d9e4a3f85976a681ee5703b",
              "IPY_MODEL_b225db327cb14cd692171f66add98c02",
              "IPY_MODEL_082d77cdfd784312a727b29e3ef5be3a"
            ],
            "layout": "IPY_MODEL_ffa06e7ae5b043d2877f14bb94c44835"
          }
        },
        "adc432b07d9e4a3f85976a681ee5703b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e36dd68c17c4dc5834f55b96044baee",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0f72dfc66aa347868ca368a5dc293b3d",
            "value": "README.md:â€‡100%"
          }
        },
        "b225db327cb14cd692171f66add98c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb381237a53402d9921c11539413a56",
            "max": 7940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e8850b73f304a9dafeb0a7aec22638b",
            "value": 7940
          }
        },
        "082d77cdfd784312a727b29e3ef5be3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a64c71058e44f6faa7299f2c8336958",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8812c2de0d48420ab86ecfb5f2f04e48",
            "value": "â€‡7.94k/7.94kâ€‡[00:00&lt;00:00,â€‡898kB/s]"
          }
        },
        "ffa06e7ae5b043d2877f14bb94c44835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e36dd68c17c4dc5834f55b96044baee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f72dfc66aa347868ca368a5dc293b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdb381237a53402d9921c11539413a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e8850b73f304a9dafeb0a7aec22638b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a64c71058e44f6faa7299f2c8336958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8812c2de0d48420ab86ecfb5f2f04e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}