{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install together"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "3HNTDF-VK38X",
        "outputId": "81592747-68c3-456e-96da-75b5a7870e06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.3.11-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.11.11)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from together) (0.2.2)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (1.26.4)\n",
            "Collecting pillow<11.0.0,>=10.3.0 (from together)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from together) (17.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.10.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.3.11-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow, together\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "Successfully installed pillow-10.4.0 together-1.3.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "f05f6fcdee734702bad85256b1f8b833"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')"
      ],
      "metadata": {
        "id": "RZ3S52UZLJG9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7Z9AEW-XKxfI"
      },
      "outputs": [],
      "source": [
        "from together import Together\n",
        "\n",
        "client = Together(api_key = TOGETHER_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "    messages=[\n",
        "        {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"tell me a joke\"\n",
        "        },\n",
        "        {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": \"Here‚Äõs one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta!\\n\\nHope that made you laugh! Do you want to hear another one?\"\n",
        "        },\n",
        "        {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"yes\"\n",
        "        },\n",
        "        {}\n",
        "],\n",
        "    max_tokens=1024,\n",
        "    temperature=0.7,\n",
        "    top_p=0.7,\n",
        "    top_k=50,\n",
        "    repetition_penalty=1,\n",
        "    stop=[\"<|eot_id|>\",\"<|eom_id|>\"],\n",
        "    utm_source=\"newsletter\",\n",
        "    utm_medium=\"email\",\n",
        "    utm_campaign=\"january-2025-newsletter\",\n",
        "    stream=True\n",
        ")"
      ],
      "metadata": {
        "id": "8Z0rDp2PLCBX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in response:\n",
        "    if hasattr(token, 'choices'):\n",
        "        print(token.choices[0].delta.content, end='', flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH5NtkZiLa-s",
        "outputId": "b094486f-7dad-490c-c00c-2ebb3f27d00b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's another one:\n",
            "\n",
            "Why couldn't the bicycle stand up by itself?\n",
            "\n",
            "Because it was two-tired!\n",
            "\n",
            "Hope that one pedaled its way into your heart! Want to hear another?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from together import Together\n",
        "\n",
        "class Chatbot:\n",
        "    def __init__(self, api_key: str):\n",
        "        \"\"\"\n",
        "        Initialize the Chatbot object.\n",
        "\n",
        "        Args:\n",
        "            api_key (str): API key for the Together API.\n",
        "        \"\"\"\n",
        "        self.api_key = api_key\n",
        "        self.client = Together(api_key=api_key)\n",
        "        self.history = []  # List to store conversation history\n",
        "\n",
        "    def chat(self, prompt: str, model: str = \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "             max_tokens: int = 1024, temperature: float = 0.7, top_p: float = 0.7,\n",
        "             top_k: int = 50, repetition_penalty: float = 1.0, stop: list = None,\n",
        "             utm_source: str = \"newsletter\", utm_medium: str = \"email\", utm_campaign: str = \"default-campaign\",\n",
        "             stream: bool = True) -> None:\n",
        "        \"\"\"\n",
        "        Send a prompt to the Together API and get a response.\n",
        "\n",
        "        Args:\n",
        "            prompt (str): User's input prompt.\n",
        "            model (str): Model to use for the API call.\n",
        "            max_tokens (int): Maximum tokens in the response.\n",
        "            temperature (float): Sampling temperature.\n",
        "            top_p (float): Nucleus sampling probability.\n",
        "            top_k (int): Number of highest probability vocabulary tokens to keep for top-k sampling.\n",
        "            repetition_penalty (float): Penalty for repetition.\n",
        "            stop (list): List of stop tokens.\n",
        "            utm_source (str): UTM source for tracking.\n",
        "            utm_medium (str): UTM medium for tracking.\n",
        "            utm_campaign (str): UTM campaign for tracking.\n",
        "            stream (bool): Whether to stream the response.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # Append the user's input to the history\n",
        "        self.history.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        # Set default stop tokens if none provided\n",
        "        if stop is None:\n",
        "            stop = [\"<|eot_id|>\", \"<|eom_id|>\"]\n",
        "\n",
        "        # Make the API call\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=self.history,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            repetition_penalty=repetition_penalty,\n",
        "            stop=stop,\n",
        "            utm_source=utm_source,\n",
        "            utm_medium=utm_medium,\n",
        "            utm_campaign=utm_campaign,\n",
        "            stream=stream\n",
        "        )\n",
        "\n",
        "        # Get and print the assistant's response\n",
        "        assistant_response = self.print_prompt(response)\n",
        "        print(assistant_response)\n",
        "\n",
        "        # Append the assistant's response to the history\n",
        "        self.history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "    def print_prompt(self, response) -> str:\n",
        "        \"\"\"\n",
        "        Retrieve and return the assistant's response token by token.\n",
        "\n",
        "        Args:\n",
        "            response: The API response object.\n",
        "\n",
        "        Returns:\n",
        "            str: The complete assistant response as a string.\n",
        "        \"\"\"\n",
        "        assistant_response = \"\"\n",
        "        for token in response:\n",
        "            if hasattr(token, 'choices'):\n",
        "                content = token.choices[0].delta.content\n",
        "                assistant_response += content\n",
        "        return assistant_response\n",
        "\n",
        "    def get_history(self) -> None:\n",
        "        \"\"\"\n",
        "        Display the conversation history.\n",
        "        \"\"\"\n",
        "        for entry in self.history:\n",
        "            role = entry[\"role\"].capitalize()\n",
        "            content = entry[\"content\"]\n",
        "            print(f\"{role}: {content}\\n\")"
      ],
      "metadata": {
        "id": "uv7bf9-cMSiE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start\n",
        "chatbot = Chatbot(api_key=TOGETHER_API_KEY)"
      ],
      "metadata": {
        "id": "h8G4YatlMWQR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User prompt\n",
        "user_prompt = \"write a py code for me to find the next fib number\"\n",
        "response = chatbot.chat(prompt=user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0Obvdd7MZnv",
        "outputId": "a2f23957-838b-4aa9-bf6b-78347dc33faa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Fibonacci Sequence Generator**\n",
            "================================\n",
            "\n",
            "Below is a Python function that generates the next Fibonacci number in the sequence.\n",
            "\n",
            "```python\n",
            "def next_fib(n):\n",
            "    \"\"\"\n",
            "    Generate the next Fibonacci number in the sequence.\n",
            "\n",
            "    Args:\n",
            "        n (int): The position of the Fibonacci number to generate.\n",
            "\n",
            "    Returns:\n",
            "        int: The nth Fibonacci number.\n",
            "    \"\"\"\n",
            "    if n <= 0:\n",
            "        raise ValueError(\"Input should be a positive integer.\")\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 2:\n",
            "        return 1\n",
            "    else:\n",
            "        a, b = 0, 1\n",
            "        for _ in range(2, n):\n",
            "            a, b = b, a + b\n",
            "        return b\n",
            "\n",
            "def main():\n",
            "    n = int(input(\"Enter the position of the Fibonacci number to generate: \"))\n",
            "    print(f\"The {n}th Fibonacci number is: {next_fib(n)}\")\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "```\n",
            "\n",
            "**How it works:**\n",
            "\n",
            "1. The `next_fib` function takes an integer `n` as input, representing the position of the Fibonacci number to generate.\n",
            "2. It checks for base cases where `n` is less than or equal to 0 (invalid input), 1 (returns 0), or 2 (returns 1).\n",
            "3. For `n` greater than 2, it initializes two variables `a` and `b` to 0 and 1, respectively, representing the first two Fibonacci numbers.\n",
            "4. It then enters a loop that runs `n-2` times, updating `a` and `b` to `b` and `a + b`, respectively, in each iteration.\n",
            "5. Finally, it returns the `n`th Fibonacci number, which is stored in `b`.\n",
            "\n",
            "**Example usage:**\n",
            "\n",
            "Run the code and enter the position of the Fibonacci number you want to generate when prompted. For example, if you enter `10`, the output will be `34`, which is the 10th Fibonacci number.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show history\n",
        "print(\"\\nConversation History:\")\n",
        "chatbot.get_history()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuO5d6EJMawt",
        "outputId": "835aaa2f-1aed-443c-bd44-f12cb01ea975"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Conversation History:\n",
            "User: what is 1+1\n",
            "\n",
            "Assistant: 1 + 1 = 2.\n",
            "\n",
            "User: write a py code for me to find the next fib number\n",
            "\n",
            "Assistant: **Fibonacci Sequence Generator**\n",
            "================================\n",
            "\n",
            "Below is a Python function that generates the next Fibonacci number in the sequence.\n",
            "\n",
            "```python\n",
            "def next_fib(n):\n",
            "    \"\"\"\n",
            "    Generate the next Fibonacci number in the sequence.\n",
            "\n",
            "    Args:\n",
            "        n (int): The position of the Fibonacci number to generate.\n",
            "\n",
            "    Returns:\n",
            "        int: The nth Fibonacci number.\n",
            "    \"\"\"\n",
            "    if n <= 0:\n",
            "        raise ValueError(\"Input should be a positive integer.\")\n",
            "    elif n == 1:\n",
            "        return 0\n",
            "    elif n == 2:\n",
            "        return 1\n",
            "    else:\n",
            "        a, b = 0, 1\n",
            "        for _ in range(2, n):\n",
            "            a, b = b, a + b\n",
            "        return b\n",
            "\n",
            "def main():\n",
            "    n = int(input(\"Enter the position of the Fibonacci number to generate: \"))\n",
            "    print(f\"The {n}th Fibonacci number is: {next_fib(n)}\")\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "```\n",
            "\n",
            "**How it works:**\n",
            "\n",
            "1. The `next_fib` function takes an integer `n` as input, representing the position of the Fibonacci number to generate.\n",
            "2. It checks for base cases where `n` is less than or equal to 0 (invalid input), 1 (returns 0), or 2 (returns 1).\n",
            "3. For `n` greater than 2, it initializes two variables `a` and `b` to 0 and 1, respectively, representing the first two Fibonacci numbers.\n",
            "4. It then enters a loop that runs `n-2` times, updating `a` and `b` to `b` and `a + b`, respectively, in each iteration.\n",
            "5. Finally, it returns the `n`th Fibonacci number, which is stored in `b`.\n",
            "\n",
            "**Example usage:**\n",
            "\n",
            "Run the code and enter the position of the Fibonacci number you want to generate when prompted. For example, if you enter `10`, the output will be `34`, which is the 10th Fibonacci number.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming chatbot is already defined and configured\n",
        "print(\"üëã Welcome to the Chatbot! Type your prompt below. Type 'EXIT' to quit anytime. üõë\")\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_prompt = input(\"üí¨ Your prompt: \")\n",
        "\n",
        "    # Check if the user wants to exit\n",
        "    if user_prompt.strip().upper() == \"EXIT\":\n",
        "        print(\"üëã Exiting the program. Goodbye! üö™\")\n",
        "        break\n",
        "\n",
        "    # Make the API call and get the response\n",
        "    response = chatbot.chat(prompt=user_prompt)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-tTJoFNSN_3",
        "outputId": "b54bad61-23c4-41a0-bcbd-b83e0eeab007"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üëã Welcome to the Chatbot! Type your prompt below. Type 'EXIT' to quit anytime. üõë\n",
            "üí¨ Your prompt: write a poem about tonight's sky\n",
            "The sky is painted, a deep shade of night\n",
            "A canvas of wonder, a celestial delight\n",
            "The stars are twinkling, like diamonds so bright\n",
            "A million points of light, in the dark of the night\n",
            "\n",
            "The moon is full, a glowing orb of white\n",
            " Casting a silver glow, on the world below in sight\n",
            "The constellations, a map of old\n",
            "Guiding us through, the stories yet untold\n",
            "\n",
            "The night air is crisp, with a hint of cool breeze\n",
            "As the world slows down, and the stars shine with ease\n",
            "The sky is a treasure, a sight to behold\n",
            "A reminder of magic, that never grows old\n",
            "\n",
            "The darkness is filled, with a thousand points of light\n",
            "A celestial showcase, on this wondrous night\n",
            "The stars are whispering, secrets to the wind\n",
            "As the moon listens closely, with a gentle grin\n",
            "\n",
            "The sky is a mystery, a wonder to explore\n",
            "A place where dreams are made, and magic is stored\n",
            "Tonight's sky is a gift, a treasure to see\n",
            "A reminder of the beauty, that's waiting for me.\n",
            "üí¨ Your prompt: EXIT\n",
            "üëã Exiting the program. Goodbye! üö™\n"
          ]
        }
      ]
    }
  ]
}