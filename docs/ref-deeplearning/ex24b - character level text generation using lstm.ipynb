{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mM_9l4J22yh"
      },
      "source": [
        "# Character-level text generation with LSTM\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2015/06/15<br>\n",
        "**Last modified:** 2020/04/30<br>\n",
        "**Description:** Generate text from Nietzsche's writings with a character-level LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnUwiUMK22yj"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example demonstrates how to use a LSTM model to generate\n",
        "text character-by-character.\n",
        "\n",
        "At least 20 epochs are required before the generated text\n",
        "starts sounding locally coherent.\n",
        "\n",
        "It is recommended to run this script on GPU, as recurrent\n",
        "networks are quite computationally intensive.\n",
        "\n",
        "If you try this script on new data, make sure your corpus\n",
        "has at least ~100k characters. ~1M is better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEJuJSb522yk"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X6uNhcnH22yk"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLWE-xc822yl"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ku30zvks22yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf3c3b6-3cc7-4432-d1aa-d62db285b647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "600901/600901 [==============================] - 0s 1us/step\n",
            "Corpus length: 600893\n",
            "Total chars: 56\n",
            "Number of sequences: 200285\n"
          ]
        }
      ],
      "source": [
        "path = keras.utils.get_file(\n",
        "    \"nietzsche.txt\",\n",
        "    origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\",\n",
        ")\n",
        "with io.open(path, encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
        "print(\"Corpus length:\", len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=\"bool\")\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=\"bool\")\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMLTlvsY22yl"
      },
      "source": [
        "## Build the model: a single LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qxp0nIHe22yl"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(maxlen, len(chars))),\n",
        "        layers.LSTM(128),\n",
        "        layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feU6KBi222ym"
      },
      "source": [
        "## Prepare the text sampling function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-xWMU4ht22ym"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAi44LzZ22ym"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trUGpboG22ym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a99c05-6147-485b-a75c-173361350b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1565/1565 [==============================] - 9s 5ms/step - loss: 1.9583\n",
            "\n",
            "Generating text after epoch: 0\n",
            "...Diversity: 0.2\n",
            "...Generating with seed: \"erous to the maintenance of the communit\"\n",
            "...Generated:  y of the resting of prepertion as the resting of a comporture the restinction and the resticion and the restinct of the restinct and and the resting of the restinct and and the resting and the respection as a conceptions and the respect of the resting of a corring of the resting of the restinct of the resticions of the reason and the restinct of the resticions and and the distrence the restinct an\n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"erous to the maintenance of the communit\"\n"
          ]
        }
      ],
      "source": [
        "epochs = 40\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
        "    print()\n",
        "    print(\"Generating text after epoch: %d\" % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print(\"...Diversity:\", diversity)\n",
        "\n",
        "        generated = \"\"\n",
        "        sentence = text[start_index : start_index + maxlen]\n",
        "        print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.0\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "            sentence = sentence[1:] + next_char\n",
        "            generated += next_char\n",
        "\n",
        "        print(\"...Generated: \", generated)\n",
        "        print(\"-\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}